# Getting Started 

## Setup for AI Model Usage
#### Run Ollama Server 
- Open New Terminal
- `curl -fsSL https://ollama.com/install.sh | sh`
- `ollama serve`

#### Pull and Chat with a Large Language Model (LLM) Conversational AI
- Open New Terminal
- `ollama pull gemma2:2b`

## Steps to Run the Backend
- Open new terminal.
- Navigate to the backend directory: `cd backend`
- Install dependencies: `npm install`
- Start the server: `npm start`
   - The server will run at [http://localhost:8080/](http://localhost:8080/).

